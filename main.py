import os
import json
import pdfplumber
import pandas as pd
import shutil
from docx import Document
import re
from fastapi import FastAPI, HTTPException, Query,Header,File,  UploadFile,Form
from fastapi.responses import JSONResponse, FileResponse
from typing import List, Optional
from dotenv import load_dotenv
from openai import OpenAI
from pydantic import BaseModel
import io
# Load API Key
# load_dotenv()
# api_key = os.getenv("OPENAI_API_KEY")
# if not api_key:
#     raise ValueError("Thi·∫øu OPENAI_API_KEY trong .env")
# client = OpenAI(api_key=api_key)

# Setup FastAPI
app = FastAPI()

# Folders
# TEMP_DIR = "temp"
# OUTPUT_DIR = "output"
# os.makedirs(TEMP_DIR, exist_ok=True)
# os.makedirs(OUTPUT_DIR, exist_ok=True)
# üîπ Upload File API
# @app.post("/upload-file/")
# async def upload_file(file: UploadFile = File(...)):
#     """API ƒë·ªÉ kh√°ch h√†ng upload file l√™n server tr∆∞·ªõc khi x·ª≠ l√Ω."""
#     file_path = os.path.join(TEMP_DIR, file.filename)
#     with open(file_path, "wb") as buffer:
#         shutil.copyfileobj(file.file, buffer)
    
#     return {"message": "File uploaded successfully", "file_path": file_path}
# Text cleaning function
def clean_text(text: str) -> str:
    return re.sub(r'[\x00-\x08\x0b\x0c\x0e-\x1f]', '', text).strip()

# File extraction function
async def extract_text_from_uploadfile(uploaded_file: UploadFile) -> str:
    # ext = file_path.split('.')[-1].lower()
    filename = uploaded_file.filename or ""
    ext = filename.split('.')[-1].lower()
    try:
        file_bytes = await uploaded_file.read()  # ƒê·ªçc to√†n b·ªô file v√†o bi·∫øn bytes
        file_stream = io.BytesIO(file_bytes)    
        if ext == "pdf":
            with pdfplumber.open(file_stream) as pdf:
                return "\n".join(clean_text(page.extract_text() or "") for page in pdf.pages)
        elif ext == "docx":
            doc = Document(file_stream)
            return "\n".join(clean_text(p.text) for p in doc.paragraphs)
        elif ext == "txt":
            with open(file_stream, "r", encoding="utf-8") as f:
                return clean_text(f.read())
        elif ext == "xlsx":
            df = pd.read_excel(file_stream, dtype=str)
            return clean_text(df.to_string(index=False))
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"L·ªói x·ª≠ l√Ω {ext.upper()}: {e}")
    
    raise HTTPException(status_code=400, detail="ƒê·ªãnh d·∫°ng kh√¥ng h·ªó tr·ª£")

# ‚úÖ Updated: Correctly handle multiple file paths in query parameters
@app.post("/get-extracted-text/")
async def get_extracted_text(files: List[UploadFile] = File(...)):
    """Extracts text from multiple files and returns combined text."""
    # extracted_texts = []
    # for file_path in file_paths:
        # if not os.path.exists(file_path):
        #     raise HTTPException(status_code=404, detail=f"Kh√¥ng t√¨m th·∫•y {file_path}")
        # extracted_texts.append(extract_text_from_file(file_path))
        # full_path = os.path.join(TEMP_DIR, os.path.basename(file_path))  # ƒê·∫£m b·∫£o ƒë∆∞·ªùng d·∫´n ƒë√∫ng trong Heroku
        # if not os.path.exists(full_path): 
        #     raise HTTPException(status_code=404, detail=f"Kh√¥ng t√¨m th·∫•y {full_path}")
        # extracted_texts.append(extract_text_from_file(full_path))
    if not files:
        raise HTTPException(status_code=400, detail="Ch∆∞a upload file n√†o.")

    all_extracted_texts = []
    for f in files:
        text = await extract_text_from_uploadfile(f)
        all_extracted_texts.append(text)

    # G·ªôp text t·∫•t c·∫£ file
    combined_text = "\n\n".join(all_extracted_texts)
    return {"extracted_text": combined_text}

    # return {"extracted_text": "\n\n".join(extracted_texts)}
# ‚úÖ X·ª≠ l√Ω API Key do ng∆∞·ªùi d√πng cung c·∫•p
def get_openai_client(user_api_key: str):
    """T·∫°o OpenAI client s·ª≠ d·ª•ng API Key do ng∆∞·ªùi d√πng cung c·∫•p."""
    if not user_api_key:
        raise HTTPException(status_code=400, detail="B·∫°n c·∫ßn cung c·∫•p OpenAI API Key.")
    return OpenAI(api_key=user_api_key)
# OpenAI JSON extraction
def clean_json_response(response_text):
    """L√†m s·∫°ch ph·∫£n h·ªìi GPT ƒë·ªÉ lo·∫°i b·ªè c√°c k√Ω t·ª± kh√¥ng mong mu·ªën tr∆∞·ªõc khi ph√¢n t√≠ch JSON."""
    response_text = re.sub(r'[\x00-\x08\x0b\x0c\x0e-\x1f]', '', response_text)
    response_text = response_text.strip()
    if response_text.startswith("```json"):
        response_text = response_text[7:]
    if response_text.endswith("```"):
        response_text = response_text[:-3]
    return response_text.strip()
def extract_info_with_openai(text: str,user_api_key: str) -> dict:
    prompt = f"""
    Tr√≠ch xu·∫•t th√¥ng tin t·ª´ vƒÉn b·∫£n CV v√† tr·∫£ v·ªÅ JSON h·ª£p l·ªá:
    {{
        "Name": "",
        "Email": "",
        "Phone": "",
        "Skills": [],  
        "Experience": [],  
        "Education": [],  
        "Certifications": [],  
        "Languages": [],  
        "Strengths": [],  
        "Weaknesses": [],  
        "Additional information": []
    }}
    For the **Languages** field, include:
    - The candidate's native language based on their nationality (e.g., Vietnamese for a candidate from Vietnam).
    - Any foreign language certifications (e.g., TOEIC score) and the corresponding language proficiency level (e.g., English with a proficiency level based on the score).

    For **Strengths and Weaknesses**, analyze the candidate's work experience to identify:
    - **Strengths:** Key skills and attributes demonstrated through their experience.
    - **Weaknesses:** Areas for improvement or challenges faced in their roles.
    VƒÉn b·∫£n CV:
    {text}
    """
    client = get_openai_client(user_api_key)
    response = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[
             {"role": "system", "content": "You are an expert in extracting information from CVs (resumes) and images with 10 years of experience in getting the exact information needed to recruit suitable positions for the company."

            "**Context:** I will provide you with resumes of candidates (which can be one or more) or image files containing text."

            "**Your task** is to extract information from the resumes and images I provide (I have taken the text from the resume, and the image will be provided to you below) and return the output as a JSON file."

            "Some of the most important information required for each candidate includes:"
            "- Name"
            "- Email"
            "- Phone number"
            "- Skills"
            "- Experience (including: position, timeline, responsibilities)"
            "- Education (including: degree, institution, timeline, GPA)"
            "- Certifications"
            "- Languages (including proficiency based on nationality and language certifications)"
            "- Strengths (based on the candidate's experience and job description)"
            "- Weaknesses (based on the candidate's experience and job description)"
            "- Additional information (including identification and visa details if provided)"

            "**Task:** Extract the following information from the CV text and return it as JSON."

            "**Output:** JSON file format"

            "***Note:** I can provide you with the text, but in that text will be a synthesis of many resumes of different candidates.*"

            "**REMEMBER:** The output should only be in JSON format."},
            {"role": "user", "content": prompt}]
    )
    extracted_text = response.choices[0].message.content.strip()
    cleaned_text = clean_json_response(extracted_text)
    try:
        return json.loads(cleaned_text)
    except json.JSONDecodeError as e:
        raise HTTPException(status_code=500, detail=f"L·ªói ph√¢n t√≠ch JSON: {e}")

# ‚úÖ Updated: Correctly handle multiple file paths in query parameters
@app.post("/get-json/")
async def get_json_from_files(
    files: List[UploadFile] = File(...),
    openai_api_key: Optional[str] = Header(None, convert_underscores=False)):
    if not files:
        raise HTTPException(status_code=400, detail="Ch∆∞a upload file n√†o.")
    if not openai_api_key:
        raise HTTPException(
            status_code=400,
            detail="Thi·∫øu OpenAI API Key. Vui l√≤ng truy·ªÅn 'openai_api_key' trong Header."
        )

    all_texts = []
    for f in files:
        text = await extract_text_from_uploadfile(f)
        all_texts.append(text)

    # G·ªôp to√†n b·ªô text
    full_text = "\n\n".join(all_texts)

    # G·ªçi h√†m tr√≠ch xu·∫•t JSON qua OpenAI
    extracted_info = extract_info_with_openai(full_text, openai_api_key)
    
    # Tr·∫£ v·ªÅ JSON (kh√¥ng c·∫ßn ghi ra file)
    return JSONResponse(content=extracted_info)


# ‚úÖ Updated: Ensure correct naming for file parameter
class QuestionRequest(BaseModel):
    filename: str
    question: str

@app.post("/ask-question/")
async def  ask_question(
    file: UploadFile = File(...),
    question: str = Form(...),  # L·∫•y c√¢u h·ªèi d∆∞·ªõi d·∫°ng text
    openai_api_key: Optional[str] = Header(None, convert_underscores=False)
):
    """Extracts text from a file and answers a question using OpenAI."""
    if not openai_api_key:
        raise HTTPException(status_code=400, detail="Thi·∫øu OpenAI API Key. Vui l√≤ng cung c·∫•p qua 'openai_api_key' trong header.")
    # if not os.path.exists(request.filename):
    #     raise HTTPException(status_code=404, detail=f"Kh√¥ng t√¨m th·∫•y {request.filename}")
    if not file:
        raise HTTPException(status_code=400, detail="Ch∆∞a upload file n√†o.")
    # full_path = os.path.join(TEMP_DIR, os.path.basename(request.filename))
    # if not os.path.exists(full_path):
    #     raise HTTPException(status_code=404, detail=f"Kh√¥ng t√¨m th·∫•y {full_path}")

    # extracted_text = extract_text_from_uploadfile(file)
    extracted_text = await extract_text_from_uploadfile(file)
    # user_question = question_req.question
    try:
        client = OpenAI(api_key=openai_api_key)
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": f"Play the role of a professional HR, with 10 years of experience in finding potential candidates suitable for the company based on the CV (resume) they send Context: I will provide you with information of each CV (resume) in text form, from which I will ask you some questions related to the CV (resume) of this candidate Task: Please provide the most accurate and closest information to the question I asked, helping me have the most objective view of this candidate so that I can decide whether to hire him or not Tone: solemn, dignified, straightforward, suitable for the office environment, recruitment. Below is the content of the candidate's CV\n{extracted_text}"},
                {"role": "user", "content": question}
            ]
        )
        answer = response.choices[0].message.content.strip()
        return {"answer": answer}
        # return {"answer": response.choices[0].message.content.strip()}
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"L·ªói khi g·ªçi OpenAI API: {str(e)}")

if __name__ == "__main__":
    import uvicorn
    port = int(os.environ.get("PORT", 5000))  # L·∫•y PORT t·ª´ Heroku ho·∫∑c m·∫∑c ƒë·ªãnh 8000 n·∫øu ch·∫°y local
    uvicorn.run(app, host="0.0.0.0", port=port)
